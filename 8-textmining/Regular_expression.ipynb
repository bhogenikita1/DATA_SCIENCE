{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea7c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"The agent's phone number is 408-555-1234.Call soon!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0ad3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'phone'in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c221cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3573b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern='phone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d85762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(12, 17), match='phone'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(pattern,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715465f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=\"NOT IN TEXT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f80a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern='phone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8f1a772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(12, 17), match='phone'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match=re.search(pattern,text)\n",
    "match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8e5a7",
   "metadata": {},
   "source": [
    "Now we have seeen that re.serach() will take the pattern,scan the text and then \n",
    "returns a match object if no pattren is found a none is returned\n",
    "\n",
    "if the pattern is not in the text it will not showing any error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e38ab02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#span()=> to get the start and end positions of the match.\n",
    "match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df20601b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb5f876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d87033",
   "metadata": {},
   "source": [
    "but what when patterns occurs more than once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9817088",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"my phone is new phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fdc64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "match=re.search(\"phone\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "602c4846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.span()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa48327",
   "metadata": {},
   "source": [
    "notice if only matches first instance if we wanted a list of all matches we can use .findall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb88141c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phone', 'phone']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches=re.findall(\"phone\",text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22d4848e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11208b1",
   "metadata": {},
   "source": [
    "to get actual objects use the iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20072f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n",
      "(16, 21)\n"
     ]
    }
   ],
   "source": [
    "for match in re.finditer(\"phone\",text):\n",
    "    print(match.span())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd6bdb",
   "metadata": {},
   "source": [
    "if we wanted the actaul text that matched you can use the.group()method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2deb8396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phone'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09fba22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"The telephone number is 408-555-1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24f2528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone=re.search(r'\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ac1cd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408-555-1234'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab91d513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(24, 36), match='408-555-1234'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\d{3}-\\d{3}-\\d{4}',text)\n",
    "#serach is for text/pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9376277",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_pattern=re.compile(r'(\\d{3})-(\\d{3})-(\\d{4})')\n",
    "#for pattern only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4f4208ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=re.search(phone_pattern,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04ee35b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408-555-1234'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The entire result\n",
    "results.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7604fbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f645568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408-555-1234'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d53503d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'555'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6ad683a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336f8f9",
   "metadata": {},
   "source": [
    "Or pattern- use the pipe operator to have an or statement for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ebabad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(5, 8), match='man'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"man|woman\",\"This man was here.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a6f5b5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(5, 10), match='woman'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"man|woman\",\"This woman was here.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c772d0db",
   "metadata": {},
   "source": [
    "the wildcard character use a\"wildcard\" as a placement that will match nay charcter placed there, you can use a simple period. for this . for example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "072b7555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'hat', 'sat']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\".at\",\"The cat in the hat sat here.\")\n",
    "#1 letter before at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7e08712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat', 'lat']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\".at\",\"The bat went splat\")\n",
    "#1 letter before at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d33e8",
   "metadata": {},
   "source": [
    "notice how we only match the first 3 letters  that is because\n",
    "we need a. for each wildcard letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36996a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e bat', 'splat']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"...at\",\"The bat went splat\")\n",
    "#3 letters before at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e489fba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat', 'splat']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one or more non-whitespaces that ends with 'at'\n",
    "re.findall(r'\\S+at',\"The bat went splat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab8015a",
   "metadata": {},
   "source": [
    "Starts with and ends with we can use the ^ to single starts with, and the $ to single ends with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21726218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### 27/08/2024 #########\n",
    "\n",
    "#ends with a number\n",
    "import re\n",
    "re.findall(r'\\d$','This ends with a number 2')\n",
    "#^  it means following pattern must be at the beginning of the string\n",
    "#^\\d means: \"look for a digit at the start of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b4d0753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^\\d','1 is the loneliest number')\n",
    "#^\\d looks for a digit at the start of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24934253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'l',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " 'l',\n",
       " 'i',\n",
       " 'e',\n",
       " 's',\n",
       " 't',\n",
       " ' ',\n",
       " 'n',\n",
       " 'u',\n",
       " 'm',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[^\\d]','1 is the loneliest number')\n",
    "#it will give all string except number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c4199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase=\"there are  3 numbers 34 inside 5 this sentence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9dd100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=re.findall(r'[^\\d]+',phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b395353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there are  ', ' numbers ', ' inside ', ' this sentence.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba8017",
   "metadata": {},
   "source": [
    "to get the words back together use +sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bd2f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrase=\"this is string but it has punctuation how cann we remove it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f1bfbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'string',\n",
       " 'but',\n",
       " 'it',\n",
       " 'has',\n",
       " 'punctuation',\n",
       " 'how',\n",
       " 'cann',\n",
       " 'we',\n",
       " 'remove',\n",
       " 'it']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[^!.? ]+',test_phrase)\n",
    "\n",
    "'''\n",
    "!.? : These are specific characters to exclude. The pattern says not to match:\n",
    "! (exclamation mark)\n",
    ". (period)\n",
    "? (question mark)\n",
    "( ) Space\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7a4feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean=''.join(re.findall('[^!.?]+',test_phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2e846d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is string but it has punctuation how cann we remove it'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a63c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find words that start with cat and end with one of this option:'fish,'nap','caterpiller'\n",
    "text='Hello, would you like some catfish'\n",
    "texttwo=\"Hello would you like to take a catnap?\"\n",
    "textthree=\"Hello,have you seen this caterpiller\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e104fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(27, 34), match='catfish'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'cat(fish|nap|claw)',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06df8886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(31, 37), match='catnap'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'cat(fish|nap|claw)',texttwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c4ae67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(25, 36), match='caterpiller'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'cat(fish|nap|erpiller)',textthree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0269e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#piip install -U spacy\n",
    "#conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ec5ff2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.S.startup\n",
      "for\n",
      "$\n",
      "6\n",
      "million\n"
     ]
    }
   ],
   "source": [
    "#import spaCy and load the langauge library\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "#create the Doc object\n",
    "doc = nlp(u'Tesla is looking at buying U.S.startup for $6 million')\n",
    "\n",
    "#print each token separately\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac66d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN\n",
      "is AUX\n",
      "looking VERB\n",
      "at ADP\n",
      "buying VERB\n",
      "U.S.startup NOUN\n",
      "for ADP\n",
      "$ SYM\n",
      "6 NUM\n",
      "million NUM\n"
     ]
    }
   ],
   "source": [
    "#import spaCy and load the langauge library\n",
    "\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "#create the Doc object\n",
    "doc=nlp(u'Tesla is looking at buying U.S.startup for $6 million')\n",
    "\n",
    "#print each token separately\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a2ea88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S.startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "#import spaCy and load the langauge library\n",
    "\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "#create the Doc object\n",
    "doc=nlp(u'Tesla is looking at buying U.S.startup for $6 million')\n",
    "\n",
    "#print each token separately\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_,token.dep_)\n",
    "    #predict syntactic dependencies\n",
    "    #predicting syntactic dependencies involves\n",
    "    #identifying the grammatical structure of a sentence by determinng how different words relate to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cef874d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x258151e9430>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x258151e9250>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x25814f56880>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2581524d190>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x25815247510>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x25814f566c0>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a13d871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040de6f6",
   "metadata": {},
   "source": [
    "tokenization : the first step in processing text is to split up all component parts(words & punctuation)into \"tokens\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9defff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "n't PART neg\n",
      "   SPACE dep\n",
      "looking VERB ROOT\n",
      "into ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n"
     ]
    }
   ],
   "source": [
    "doc2=nlp(u\"Tesla isn't   looking into startups anymore\")\n",
    "for token in doc2:\n",
    "    print(token.text,token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acf1698",
   "metadata": {},
   "source": [
    "Notice how isn't has been split two tokens spaCy recognizes both the root verb is and the negation attached to it.\n",
    "\n",
    "Notice also that both the extended whitespaces and the period at the end of the sentence are assigned their own tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b797f259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla isn't   looking into startups anymore"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3498e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf59671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c13e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df57baef",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1815430277.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    https://spacy.io/usage/linguistic-features#pos-tagging\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://spacy.io/usage/linguistic-features#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ca69a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d04d421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc8e7df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35620efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "print(doc2[4].text)\n",
    "print(doc2[4].lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8dad23",
   "metadata": {},
   "source": [
    "spans\n",
    "\n",
    "large Doc object can be hard to work with at times. A span is a slice of Doc object in the form Doc[start:stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c1f51cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3=nlp('although commonly attributed to john Lemmin from his song \"Beautiful Boy\",\\'life is what happens to us while we are making other plan was written by \\'cartoonlist allen sounders and published in Reader\\'Digest in 1957,when Lemmon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d43090f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us while we are making other plan was written by 'cartoonlist allen sounders\n"
     ]
    }
   ],
   "source": [
    "life_quote=doc3[16:30]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "379ab96a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (2192060941.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    doc4=nlp(u'This)\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "doc4=nlp(u'This)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d52008f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "#Create a string that includes opening and closing quotation marks\n",
    "mystring='\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a11e123a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" | We | 're | moving | to | L.A. | ! | \" | "
     ]
    }
   ],
   "source": [
    "#Create a Doc object and explore tokens\n",
    "doc=nlp(mystring)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bdb7c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We | 're | here | to | help | ! | Send | snail | - | mail | , | email | support@oursite.com | or | visit | us | at | http://www.oursite.com | ! | "
     ]
    }
   ],
   "source": [
    "doc2=nlp(u\"We're here to help! Send snail-mail,email support@oursite.com or visit us at http://www.oursite.com!\")\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text,end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995c9152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "NYC\n",
      "cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "10.30\n"
     ]
    }
   ],
   "source": [
    "doc3=nlp(u'A 5km NYC cab ride costs $10.30')\n",
    "\n",
    "for t in doc3:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b455d8",
   "metadata": {},
   "source": [
    "Here the distance unit and dollar sign are assigned their own tokens,yet the dollar amount is preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978b7a4",
   "metadata": {},
   "source": [
    "punctuation that exists as part of a known abbreviation will be kept as part of the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f841c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc4=nlp(u\"let's visit St.Louis in the U.S. next year.\")\n",
    "for t in doc4:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aee0d7",
   "metadata": {},
   "source": [
    "here the abbreviation for \"Saint\"and\"united states\" are both preserved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a0528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | for | $ | 6 | million | \n",
      "----\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "doc8=nlp(u\"Apple to build a Hong Kong for $6 million\")\n",
    "\n",
    "for token in doc8:\n",
    "    print(token.text,end=' | ')\n",
    "    \n",
    "print('\\n----')\n",
    "\n",
    "for ent in doc8.ents:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "300fff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufactures\n"
     ]
    }
   ],
   "source": [
    "doc9=nlp(u\"Autonomous cars shift insurance liability towards manufactures.\")\n",
    "\n",
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8145c5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red cars\n",
      "higher insurance rates\n"
     ]
    }
   ],
   "source": [
    "doc10=nlp(u\"Red cars do not carry higher insurance rates\")\n",
    "#group of nouns\n",
    "for chunk in doc10.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da2dfbf",
   "metadata": {},
   "source": [
    "Stemming is a somewhat crude method for catloging related words. it essential grops off lettersfrom end until the stem is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "657593b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the toolkit and the Full Porter Stemmer library\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e13b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9a644bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['run','runner','running','ran','runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f732db91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-->run\n",
      "runner-->runner\n",
      "running-->run\n",
      "ran-->ran\n",
      "runs-->run\n",
      "easily-->easili\n",
      "fairly-->fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'-->'+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea2897",
   "metadata": {},
   "source": [
    "Note-- how the stemmer recognizes 'runner'as noun not as a verb from a participle also the adbverbs 'easily' and'fairly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c8f92",
   "metadata": {},
   "source": [
    "The snowball stemmer it offers a slight improvement over the\n",
    "original Porter stemmer both in logic and speed Since nltk uses the name SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33ec5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "#the Snowball Stemmer requires that you pass a language parameter\n",
    "s_stemmer=SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47ef3fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['run','runner','running','ran','runs','easily','fairly']\n",
    "#words=['generous','eneration','generously','generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21147540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-->run\n",
      "runner-->runner\n",
      "running-->run\n",
      "ran-->ran\n",
      "runs-->run\n",
      "easily-->easili\n",
      "fairly-->fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'-->'+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760296f7",
   "metadata": {},
   "source": [
    "drawbacks-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4350e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-->i\n",
      "am-->am\n",
      "meeting-->meet\n",
      "him-->him\n",
      "tommorrow-->tommorrow\n",
      "at-->at\n",
      "the-->the\n",
      "meeting-->meet\n"
     ]
    }
   ],
   "source": [
    "phrase='I am meeting him tommorrow at the meeting'\n",
    "for word in phrase.split():\n",
    "    print(word+'-->'+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b445a",
   "metadata": {},
   "source": [
    "here the word 'meeting' appears twice- once as a verb and once as a noun and yet the stemmer treats both equally\n",
    "\n",
    "what is difference between stemming and lemmatization??\n",
    "\n",
    "#stemmming=>\n",
    "\n",
    "Stemming reduces words to their root form by chopping off suffixes, often without considering the word's meaning (e.g., \"running\" becomes \"run\").\n",
    "\n",
    "#lemmatization=>\n",
    "\n",
    "reduces words to their base or dictionary form (lemma) by considering the word's context and meaning (e.g., \"running\" becomes \"run,\" but \"better\" becomes \"good\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6a3e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform standard imports:\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "578505cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t SCONJ \t 16950148841647037698 \t because\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t SCONJ \t 10066841407251338481 \t since\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "today \t NOUN \t 11042482332948150395 \t today\n"
     ]
    }
   ],
   "source": [
    "doc1=nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n",
    "\n",
    "for token in doc1:\n",
    "    print(token.text,'\\t',token.pos_,'\\t',token.lemma,'\\t',token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8089fd0a",
   "metadata": {},
   "source": [
    "Fuction to display lemmas Since the display above the straggard and hard to read lets write function that display the information that we want normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a22482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}}{token.pos_:{6}}{token.lemma:<{22}}{token.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e38676",
   "metadata": {},
   "source": [
    "Here we are using fstring to format the printed text by setting minimum field within and adding a left-align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6c8f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I           PRON  4690420944186131903   I\n",
      "saw         VERB  11925638236994514241  see\n",
      "eighteen    NUM   9609336664675087640   eighteen\n",
      "mice        NOUN  1384165645700560590   mouse\n",
      "today       NOUN  11042482332948150395  today\n",
      "!           PUNCT 17494803046312582752  !\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"I saw eighteen mice today!\")\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f3657f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I           PRON  4690420944186131903   I\n",
      "am          AUX   10382539506755952630  be\n",
      "meeting     VERB  6880656908171229526   meet\n",
      "him         PRON  1655312771067108281   he\n",
      "tommorow    VERB  14881451523362505806  tommorow\n",
      "at          ADP   11667289587015813222  at\n",
      "the         DET   7425985699627899538   the\n",
      "meeting     NOUN  14798207169164081740  meeting\n"
     ]
    }
   ],
   "source": [
    "doc3=nlp(u\"I am meeting him tommorow at the meeting\")\n",
    "\n",
    "show_lemmas(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76b712a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That        PRON  4380130941430378203   that\n",
      "'s          AUX   10382539506755952630  be\n",
      "an          DET   15099054000809333061  an\n",
      "enormous    ADJ   17917224542039855524  enormous\n",
      "automobile  NOUN  7211811266693931283   automobile\n"
     ]
    }
   ],
   "source": [
    "doc4=nlp(u\"That's an enormous automobile\")\n",
    "show_lemmas(doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acb853e",
   "metadata": {},
   "source": [
    "Note that lemmatization does not reduce words to their \n",
    "most basic synonym -that is, enormous doesn't become bif and automobile doesn't become car"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba689e",
   "metadata": {},
   "source": [
    "---------------->\n",
    "\n",
    "stopwords==> spacy hold 326 built in stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66f1adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform standard imports:\n",
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b8caa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ever', 'amongst', 'yourselves', 'nowhere', '‘m', \"n't\", 'both', 'move', 'see', 'take', 'nevertheless', 'he', 'call', 'almost', 'side', 'really', 'hereupon', 'been', 'whom', 'down', 'them', 'also', 'n‘t', '’ve', 'after', 'next', 'something', 'once', 'during', 'give', 'why', 'neither', 'former', 'about', 'did', 'how', 'throughout', 'a', \"'re\", 'anything', '’re', 'nor', 'nothing', 'the', 'although', 'elsewhere', 'less', 'any', 'afterwards', 'somewhere', 'not', 'done', 'nobody', 'their', 'whoever', 'name', 'between', 'bottom', 'sixty', 'namely', 'beforehand', 'therefore', 'besides', 'hereafter', \"'s\", 'against', 'formerly', 'no', 'twenty', 're', 'whatever', 'wherein', 'rather', 'whereupon', 'either', 'before', '’s', 'latter', 'of', 'fifteen', 'somehow', 'otherwise', 'below', 'thereafter', 'might', 'who', 'until', 'where', 'under', 'or', 'used', 'into', 'eleven', 'back', 'if', 'regarding', 'over', '‘s', 'empty', 'well', 'every', 'btw', 'herein', \"'ve\", 'indeed', 'put', 'never', 'above', 'this', 'always', 'to', 'off', 'other', 'so', 'becomes', 'per', 'herself', 'can', 'are', 'him', 'each', 'onto', 'upon', 'whither', 'in', 'be', 'together', 'n’t', 'last', 'except', 'alone', 'else', 'but', 'made', 'as', 'has', 'twelve', 'with', 'should', '’m', 'through', 'does', 'seeming', 'am', 'several', '’d', 'itself', 'than', 'among', 'these', 'first', 'five', 'whole', 'out', 'those', 'everywhere', 'four', 'become', 'across', 'often', 'though', 'get', 'there', 'only', 'what', \"'ll\", 'more', 'doing', 'hundred', 'me', 'three', 'few', 'anyway', 'various', 'thereupon', 'everything', 'even', 'least', 'someone', 'within', 'one', 'here', 'yet', 'at', '‘ve', 'whenever', 'fifty', 'you', 'show', 'further', 'just', 'please', 'third', 'i', 'top', 'thru', 'anyhow', 'seemed', 'because', 'moreover', 'many', 'quite', 'most', 'without', 'and', 'mostly', 'amount', 'keep', 'latterly', 'thence', 'beside', 'however', 'full', 'much', 'whence', 'would', 'therein', 'yourself', 'it', 'very', 'all', 'since', 'others', 'from', 'none', 'is', 'when', 'whereafter', 'will', 'perhaps', \"'d\", 'serious', 'everyone', 'by', 'sometimes', 'on', '‘d', '’ll', 'already', 'two', 'being', 'must', 'eight', 'that', 'yours', 'nine', 'whether', 'whose', 'thus', 'due', 'himself', 'she', 'noone', 'then', 'while', 'had', 'part', 'its', 'hence', 'around', 'for', 'another', 'hers', 'which', 'too', 'such', 'our', 'was', 'whereby', 'same', 'behind', 'have', 'may', 'we', 'your', 'her', 'using', 'do', 'via', 'six', 'became', 'wherever', 'up', 'now', 'seems', 'ours', 'anywhere', 'us', 'themselves', 'seem', 'becoming', 'cannot', 'sometime', 'along', 'thereby', 'enough', '‘re', 'again', \"'m\", 'whereas', 'they', '‘ll', 'ten', 'unless', 'mine', 'go', 'still', 'ourselves', 'could', 'his', 'some', 'forty', 'ca', 'front', 'own', 'meanwhile', 'say', 'towards', 'my', 'myself', 'were', 'anyone', 'make', 'an', 'hereby', 'toward'}\n"
     ]
    }
   ],
   "source": [
    "#print the set of spaCy's default stop words\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7521656c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bd5770",
   "metadata": {},
   "source": [
    "<b>To see if a word is a stop word</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "223fb35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8c567df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50463b",
   "metadata": {},
   "source": [
    "<b>To add a stop words</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6514dea",
   "metadata": {},
   "source": [
    "when we want to add stop words to the default set. perhaps you decide that \"btw\"(common shorthand for \"by the way\") should be considered  a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9264415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the words in the stopwords\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "nlp.vocab['btw'].is_stop=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38f28bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12c4eb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e31a723",
   "metadata": {},
   "source": [
    "<b>#TO REMOVE A STOP WORD</b>\n",
    "\n",
    "Alternatively you may decide that\"beyond\" should not be considerd a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "531e7314",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'beyond'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Remove the word from set of stop words\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nlp\u001b[38;5;241m.\u001b[39mDefaults\u001b[38;5;241m.\u001b[39mstop_words\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeyond\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m nlp\u001b[38;5;241m.\u001b[39mvocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeyond\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mis_stop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'beyond'"
     ]
    }
   ],
   "source": [
    "#Remove the word from set of stop words\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "\n",
    "nlp.vocab['beyond'].is_stop=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b00c85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp.Defaults.stop_words.add(\"nikita\")\n",
    "#nlp.vocab['nikita'].is_stop=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1ad8db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79dd943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819bb734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
